{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "926ab547-6052-4da9-86b9-afee80e6cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error,  r2_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import tensorflow.keras.layers as layers\n",
    "from scipy.sparse import isspmatrix\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b07f2110-9548-444e-8d6d-658ce5e322e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "\n",
    "# Train Data \n",
    "temp_df = pd.read_csv(\"/Users/inutenneti/Desktop/Winter Quarter/Predictive Analytics 2/project/train.csv\", nrows=0)  # Read only the header\n",
    "total_columns = len(temp_df.columns)\n",
    "columns_to_use = temp_df.columns[1:total_columns] \n",
    "train_data = pd.read_csv(\"/Users/inutenneti/Desktop/Winter Quarter/Predictive Analytics 2/project/train.csv\", usecols=columns_to_use)\n",
    "\n",
    "# Test Data \n",
    "test_data = pd.read_csv(\"/Users/inutenneti/Desktop/Winter Quarter/Predictive Analytics 2/project/test.csv\", usecols=columns_to_use)\n",
    "\n",
    "# Dropping the columns that are not relevant to our analysis \n",
    "train_data = train_data.drop(columns=['building_name', 'site_name'])\n",
    "test_data = test_data.drop(columns=['building_name', 'site_name'])\n",
    "\n",
    "# Building index on building_id for furhter assessment \n",
    "#train_data.set_index('building_id', inplace=True)\n",
    "#test_data.set_index('building_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ee79ef-e6fb-45e0-bc70-09a5d0c52c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering for electrity meter_reading\n",
    "train_data = train_data[train_data['meter'] == 'solar']\n",
    "test_data = test_data[test_data['meter'] == 'solar']\n",
    "\n",
    "train_data = train_data.drop(columns=['meter'])\n",
    "test_data = test_data.drop(columns=['meter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29a8a71e-1bf9-4aed-b66b-7ebb82124a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date  meter_reading sub_primaryspaceusage      sqm      sqft  \\\n",
      "30816  2016-03-13         117.69        Student Center  17358.0  186840.0   \n",
      "30958  2016-08-02         193.06        Student Center  17358.0  186840.0   \n",
      "\n",
      "          timezone  airTemperature  cloudCoverage  dewTemperature  \\\n",
      "30816  US/Mountain       11.916960       2.035447        5.470264   \n",
      "30958  US/Mountain       23.411894       2.275106       17.420044   \n",
      "\n",
      "       precipDepth1HR  precipDepth6HR  seaLvlPressure  windDirection  \\\n",
      "30816        0.807454       12.221662     1019.473356     134.487438   \n",
      "30958        0.897203       17.677378     1014.908378     161.312014   \n",
      "\n",
      "       windSpeed  season  building_id  site_id  \n",
      "30816   3.277313  Spring           72        2  \n",
      "30958   3.426872  Summer           72        2  \n",
      "-------------------------------------------------------------\n",
      "             date  meter_reading sub_primaryspaceusage      sqm      sqft  \\\n",
      "26044  2017-05-10      3538.9423              Academic  11254.8  121146.0   \n",
      "29009  2017-06-24       130.0500              Academic  10551.9  113580.0   \n",
      "\n",
      "          timezone  airTemperature  cloudCoverage  dewTemperature  \\\n",
      "26044  US/Mountain       15.083991       1.487309        6.778509   \n",
      "29009  US/Mountain       22.365848       2.256603       14.496205   \n",
      "\n",
      "       precipDepth1HR  precipDepth6HR  seaLvlPressure  windDirection  \\\n",
      "26044        0.423537       12.045794     1014.004063     152.837539   \n",
      "29009        1.114600       18.120304     1012.155165     233.906362   \n",
      "\n",
      "       windSpeed  season  building_id  site_id  \n",
      "26044   2.682036  Spring           68        2  \n",
      "29009   4.435594  Summer           71        2  \n"
     ]
    }
   ],
   "source": [
    "# Inspecting the data frames\n",
    "print(train_data.sample(2))\n",
    "print('-------------------------------------------------------------')\n",
    "print(test_data.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c6226d-be30-43eb-ac25-375d3505d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating into X and Y dataframes \n",
    "X_train = train_data.drop(columns=['meter_reading'])  # Exclude target variable\n",
    "y_train = train_data['meter_reading']\n",
    "\n",
    "X_test = test_data.drop(columns=['meter_reading'])  # Exclude target variable\n",
    "y_test = test_data['meter_reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2eafd74-2b4e-4cd8-85a5-74f3aee323ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'site_id' from numeric to categorical \n",
    "X_train['site_id'] = X_train['site_id'].astype('category')\n",
    "X_test['site_id'] = X_test['site_id'].astype('category')\n",
    "\n",
    "# Making sure the date columns is in the right format \n",
    "X_train['date'] = pd.to_datetime(X_train['date'])\n",
    "X_test['date'] = pd.to_datetime(X_test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a819b1-8b89-4913-866b-75025a6e4c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                     datetime64[ns]\n",
      "sub_primaryspaceusage            object\n",
      "sqm                             float64\n",
      "sqft                            float64\n",
      "timezone                         object\n",
      "airTemperature                  float64\n",
      "cloudCoverage                   float64\n",
      "dewTemperature                  float64\n",
      "precipDepth1HR                  float64\n",
      "precipDepth6HR                  float64\n",
      "seaLvlPressure                  float64\n",
      "windDirection                   float64\n",
      "windSpeed                       float64\n",
      "season                           object\n",
      "building_id                       int64\n",
      "site_id                        category\n",
      "dtype: object\n",
      "Index(['date', 'sub_primaryspaceusage', 'sqm', 'sqft', 'timezone',\n",
      "       'airTemperature', 'cloudCoverage', 'dewTemperature', 'precipDepth1HR',\n",
      "       'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed',\n",
      "       'season', 'building_id', 'site_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58ae7fe-13d2-4a1a-af3b-269174937c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and types based on your dataset\n",
    "numerical_features = ['sqm', 'sqft', 'airTemperature', 'cloudCoverage', 'dewTemperature',\n",
    "                      'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
    "categorical_features = ['timezone', 'season', 'sub_primaryspaceusage', 'site_id']\n",
    "date_feature = 'date'\n",
    "id_feature = 'building_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52af2257-3f8c-41fe-a12f-9583aef0d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 'building_id' and 'date' columns\n",
    "building_ids_train = X_train[id_feature].values\n",
    "dates_train = X_train[date_feature].values\n",
    "building_ids_test = X_test[id_feature].values\n",
    "dates_test = X_test[date_feature].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b95d37-ecc0-4914-ac37-84585ee412fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'building_id' and 'date' columns for preprocessing\n",
    "X_train = X_train.drop(columns=[id_feature, date_feature])\n",
    "X_test = X_test.drop(columns=[id_feature, date_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0d053dc-d81e-4900-a948-5069b0448264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit the preprocessor on the training data and transform both training and test data\n",
    "preprocessor.fit(X_train)\n",
    "X_train_processed = preprocessor.transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "690e15d0-f313-44b4-a5c5-893dba33b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the processed data back to dense DataFrames\n",
    "X_train_processed_df = pd.DataFrame(X_train_processed, columns=preprocessor.get_feature_names_out())\n",
    "X_test_processed_df = pd.DataFrame(X_test_processed, columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aad1ab3-9fec-4234-befd-6245a092b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reattach the 'building_id' and 'date' columns to the processed data\n",
    "X_train_processed_df[id_feature] = building_ids_train\n",
    "X_train_processed_df[date_feature] = dates_train\n",
    "X_test_processed_df[id_feature] = building_ids_test\n",
    "X_test_processed_df[date_feature] = dates_test\n",
    "\n",
    "# Sort the DataFrames by 'building_id' and 'date' to ensure the correct sequence\n",
    "X_train_processed_df.sort_values(by=[id_feature, date_feature], inplace=True)\n",
    "X_test_processed_df.sort_values(by=[id_feature, date_feature], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc586e03-be9e-49b2-969c-6e8a9779abb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num__sqm', 'num__sqft', 'num__airTemperature', 'num__cloudCoverage',\n",
       "       'num__dewTemperature', 'num__precipDepth1HR', 'num__precipDepth6HR',\n",
       "       'num__seaLvlPressure', 'num__windDirection', 'num__windSpeed',\n",
       "       'cat__timezone_US/Mountain', 'cat__season_Fall', 'cat__season_Spring',\n",
       "       'cat__season_Summer', 'cat__season_Winter',\n",
       "       'cat__sub_primaryspaceusage_Academic',\n",
       "       'cat__sub_primaryspaceusage_Student Center', 'cat__site_id_2',\n",
       "       'building_id', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ea3b7-826f-48c6-8fd4-e55f47b18759",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34fac754-df0e-4d9d-b8d3-125bbfe51ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.103275  , 0.103276  , 0.2006084 , ..., 1.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.103275  , 0.103276  , 0.23011522, ..., 1.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.103275  , 0.103276  , 0.21693751, ..., 1.        , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [1.        , 1.        , 0.21150202, ..., 0.        , 1.        ,\n",
       "        1.        ],\n",
       "       [1.        , 1.        , 0.14297168, ..., 0.        , 1.        ,\n",
       "        1.        ],\n",
       "       [1.        , 1.        , 0.18044175, ..., 0.        , 1.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d306f9c-1f2b-406f-857a-098e642401d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Prepare the dataset for LightGBM\n",
    "lgb_train = lgb.Dataset(X_train_processed, label=y_train)\n",
    "lgb_eval = lgb.Dataset(X_test_processed, label=y_test, reference=lgb_train)\n",
    "\n",
    "# Specify your model parameters here\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "gbm = lgb.train(\n",
    "    params,  # Your defined parameters\n",
    "    lgb_train,  # Training dataset\n",
    "    num_boost_round=100,  # Number of boosting rounds\n",
    "    valid_sets=[lgb_eval],  # Validation dataset for early stopping\n",
    "    #early_stopping_rounds=10  # Stops training if one metric of one validation data doesn't improve in last 10 rounds\n",
    ")\n",
    "\n",
    "# Continue with prediction using the best iteration\n",
    "y_pred = gbm.predict(X_test_processed, num_iteration=gbm.best_iteration)\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Negative Mean Squared Error\n",
    "negative_mse = -mse\n",
    "\n",
    "print(f'Negative Mean Squared Error: {negative_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78446bcb-4da8-4be7-9fba-fc0c7800ee88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c0cb35-5e67-47aa-9741-97aee567d188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d357772-e7d9-475f-9eb2-01e0aaa34e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
